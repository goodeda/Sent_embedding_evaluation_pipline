ar:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.45783132530121
bg:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 47.34939759036145
de:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 47.670682730923694
el:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.30120481927711
es:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 49.07630522088353
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 47.59036144578313
fr:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.13253012048193
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 46.22489959839358
hi:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 35.381526104417674
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 43.4136546184739
ru:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.93975903614458
sw:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.562248995983936
th:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.48192771084337
tr:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.863453815261046
ur:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.441767068273094
vi:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 49.437751004016064
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 48.15261044176707
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 50.12048192771084
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 49.71887550200803
zh:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 48.75502008032129
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 48.15261044176707
ar:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.497991967871485
bg:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.33734939759036
de:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.377510040160644
el:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.81526104417671
es:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.65863453815261
fr:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.17670682730924
hi:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.45381526104418
ru:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.81526104417671
sw:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.81526104417671
th:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.4136546184739
tr:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.93574297188755
ur:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 35.381526104417674
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.855421686746986
vi:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 48.15261044176707
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 35.34136546184739
zh:
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 35.06024096385542
ar:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.200803212851405
bg:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.0
de:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 42.16867469879518
el:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 39.59839357429719
es:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 43.57429718875502
fr:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 43.13253012048193
hi:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.72289156626506
ru:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.12048192771084
sw:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 39.1566265060241
th:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 41.00401606425703
tr:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 41.9277108433735
ur:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.04016064257028
vi:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 43.77510040160642
zh:
(learning rate, dropout rate, epoch): (1e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-06, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-06, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (1e-06, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (1e-06, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (1e-06, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (1e-06, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (1e-06, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (1e-06, 0.1, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 3)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (1e-06, 0.2, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-06, 0.2, 3)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch): (1e-06, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.3, 3)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (1e-06, 0.1, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.1, 4)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (1e-06, 0.2, 4)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-06, 0.2, 4)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (1e-06, 0.3, 4)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-06, 0.3, 4)	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 44.01606425702811
ar:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.17670682730924
bg:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.855421686746986
de:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.05622489959839
el:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.89558232931727
es:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.81927710843374
fr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.859437751004016
hi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.4136546184739
ru:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.381526104417674
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.734939759036145
sw:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.89558232931727
th:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.57429718875502
tr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 34.136546184738954
ur:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.89558232931727
vi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 35.58232931726908
zh:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 35.502008032128515
ar:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.88353413654618
bg:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 39.678714859437754
de:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.6425702811245
el:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 38.23293172690763
es:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 41.80722891566265
fr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.21285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 42.00803212851405
hi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 38.714859437751
ru:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.13253012048193
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 38.99598393574297
sw:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 38.11244979919679
th:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 38.23293172690763
tr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 39.47791164658634
ur:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 34.33734939759036
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 37.83132530120482
vi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.13253012048193
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 42.04819277108434
zh:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 41.88755020080321
ar:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
bg:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
de:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
el:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
es:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
fr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
hi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
ru:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
sw:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
th:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.0
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
tr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
ur:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
vi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 49.07630522088353
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
zh:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 33.333333333333336
ar:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 43.25301204819277
bg:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 44.096385542168676
de:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 43.092369477911646
el:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 42.7710843373494
es:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.89558232931727
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 45.54216867469879
fr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 44.21686746987952
hi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 42.16867469879518
ru:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.17269076305221
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 43.6144578313253
sw:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.70281124497992
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 38.99598393574297
th:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.602409638554214
tr:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 44.096385542168676
ur:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 40.562248995983936
vi:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 49.11646586345382
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 45.7429718875502
zh:
(learning rate, dropout rate, epoch): (1e-05, 0.1, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.1, 0)	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch): (0.0001, 0.1, 0)	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch): (0.0005, 0.1, 0)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (1e-05, 0.2, 0)	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch): (5e-05, 0.2, 0)	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch): (0.0001, 0.2, 0)	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch): (0.0005, 0.2, 0)	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch): (1e-05, 0.3, 0)	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch): (5e-05, 0.3, 0)	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch): (0.0001, 0.3, 0)	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch): (0.0005, 0.3, 0)	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch): (1e-05, 0.1, 1)	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch): (5e-05, 0.1, 1)	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch): (0.0001, 0.1, 1)	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch): (0.0005, 0.1, 1)	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch): (1e-05, 0.2, 1)	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch): (5e-05, 0.2, 1)	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch): (0.0001, 0.2, 1)	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch): (0.0005, 0.2, 1)	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch): (1e-05, 0.3, 1)	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch): (5e-05, 0.3, 1)	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch): (0.0001, 0.3, 1)	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch): (0.0005, 0.3, 1)	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch): (1e-05, 0.1, 2)	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch): (5e-05, 0.1, 2)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0001, 0.1, 2)	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch): (0.0005, 0.1, 2)	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch): (1e-05, 0.2, 2)	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch): (5e-05, 0.2, 2)	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch): (0.0001, 0.2, 2)	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch): (0.0005, 0.2, 2)	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch): (1e-05, 0.3, 2)	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch): (5e-05, 0.3, 2)	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch): (0.0001, 0.3, 2)	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch): (0.0005, 0.3, 2)	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch): (1e-05, 0.1, 3)	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch): (5e-05, 0.1, 3)	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch): (0.0001, 0.1, 3)	||	accuracy: 48.15261044176707
(learning rate, dropout rate, epoch): (0.0005, 0.1, 3)	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch): (1e-05, 0.2, 3)	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch): (5e-05, 0.2, 3)	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch): (0.0001, 0.2, 3)	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch): (0.0005, 0.2, 3)	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch): (1e-05, 0.3, 3)	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch): (5e-05, 0.3, 3)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (0.0001, 0.3, 3)	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch): (0.0005, 0.3, 3)	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch): (1e-05, 0.1, 4)	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch): (5e-05, 0.1, 4)	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch): (0.0001, 0.1, 4)	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch): (0.0005, 0.1, 4)	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch): (1e-05, 0.2, 4)	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch): (5e-05, 0.2, 4)	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch): (0.0001, 0.2, 4)	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch): (0.0005, 0.2, 4)	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch): (1e-05, 0.3, 4)	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch): (5e-05, 0.3, 4)	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch): (0.0001, 0.3, 4)	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch): (0.0005, 0.3, 4)	||	accuracy: 44.377510040160644
ar siglyr:
ar siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.00401606425703
ar mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.1285140562249
bg siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.05220883534137
bg mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.81124497991968
de siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 44.618473895582326
de mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.502008032128515
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.1285140562249
el siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.69076305220884
el mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.799196787148595
es siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.622489959839356
es mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.36546184738956
fr siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 49.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.18473895582329
fr mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 49.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.092369477911646
hi siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.12449799196787
hi mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 35.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 35.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 38.674698795180724
ru siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.93172690763052
ru mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.204819277108435
sw siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 39.95983935742972
sw mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 34.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.02008032128514
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 38.19277108433735
th siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 39.397590361445786
th mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 34.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.45783132530121
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.59839357429719
tr siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.975903614457835
tr mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.1285140562249
ur siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 37.83132530120482
ur mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 38.95582329317269
vi siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 49.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.024096385542165
vi mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.53413654618474
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 49.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.626506024096386
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.44979919678715
zh siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 48.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 49.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.34939759036145
zh mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 48.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 49.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.64658634538153
ar siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 32.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.40562248995984
ar mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 32.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 34.859437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.329317269076306
bg siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.730923694779115
bg mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 34.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.975903614457835
de siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.4136546184739
de mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.00803212851405
el siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.69076305220884
el mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.51807228915663
es siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.30522088353413
es mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 40.76305220883534
fr siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.82730923694779
fr mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.24899598393574
hi siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.44578313253012
hi mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 35.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 35.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 33.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 37.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.196787148594375
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 38.95582329317269
ru siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.6144578313253
ru mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 35.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 46.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 40.803212851405625
sw siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 38.393574297188756
sw mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 37.630522088353416
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 36.54618473895582
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 35.46184738955823
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 36.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 36.10441767068273
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 37.8714859437751
th siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 39.397590361445786
th mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 34.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 34.497991967871485
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 39.07630522088353
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 34.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 34.899598393574294
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 41.967871485943775
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.6144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 34.738955823293175
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 38.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 36.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 38.91566265060241
tr siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 44.93975903614458
tr mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.734939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.738955823293175
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.04819277108434
ur siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 37.2289156626506
ur mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 34.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 35.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 38.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 34.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 33.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 36.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 38.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 35.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 36.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 35.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 36.3855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 38.95582329317269
vi siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.91566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.54216867469879
vi mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.91566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 44.497991967871485
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.34939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 42.971887550200805
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.17269076305221
zh siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.269076305220885
zh mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 33.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 33.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 33.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 34.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.53012048192771
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.204819277108435
ar siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.42168674698795
ar mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.41767068273092
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 45.18072289156626
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.493975903614455
bg siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 48.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 50.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 50.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.51004016064257
bg mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 48.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 50.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 50.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 39.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 43.4136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 46.506024096385545
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 44.57831325301205
de siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 49.558232931726906
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 49.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 50.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 49.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 51.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 51.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.31325301204819
de mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.730923694779115
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 47.670682730923694
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 49.558232931726906
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 49.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 50.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 49.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 51.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 51.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 38.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 47.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 49.87951807228916
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 50.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 50.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 47.51004016064257
el siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.15261044176707
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 50.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.59036144578313
el mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.15261044176707
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 45.70281124497992
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.863453815261046
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 50.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 38.714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 45.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.34939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 45.46184738955823
es siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 50.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 49.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 50.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 49.71887550200803
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 50.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 51.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 50.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 51.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 51.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 50.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 52.329317269076306
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 50.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 53.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.23293172690763
es mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.21285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.7710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.795180722891565
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 48.714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 48.47389558232932
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 48.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 50.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 49.1566265060241
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 50.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 49.71887550200803
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 50.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 51.76706827309237
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 50.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 51.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 51.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 50.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 52.329317269076306
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 50.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 53.25301204819277
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 45.02008032128514
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 49.07630522088353
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 51.12449799196787
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 50.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 50.24096385542169
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 47.911646586345384
fr siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 49.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 51.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.55421686746988
fr mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.57831325301205
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 46.265060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 46.86746987951807
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 49.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.83132530120482
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 51.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 38.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 37.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 44.899598393574294
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 46.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 40.200803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.17269076305221
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 49.558232931726906
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 46.30522088353413
hi siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.82329317269076
hi mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.1285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 42.610441767068274
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 43.53413654618474
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 44.33734939759036
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 47.2289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 46.82730923694779
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 45.903614457831324
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 47.630522088353416
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 43.975903614457835
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 37.55020080321285
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 36.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 43.65461847389558
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 43.855421686746986
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 44.01606425702811
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.136546184738954
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 44.45783132530121
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 43.69477911646587
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 43.092369477911646
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.373493975903614
ru siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.31325301204819
ru mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.99196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.75502008032129
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 43.29317269076305
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 44.29718875502008
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 43.493975903614455
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 42.81124497991968
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.06425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 45.381526104417674
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.35341365461847
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 45.100401606425706
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 48.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.15261044176707
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 45.140562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 46.54618473895582
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 44.53815261044177
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 43.45381526104418
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 43.77510040160642
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 44.21686746987952
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 48.55421686746988
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 48.795180722891565
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 45.94377510040161
sw siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 40.92369477911647
sw mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 35.54216867469879
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 42.208835341365464
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 41.68674698795181
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 42.04819277108434
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 43.01204819277108
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.13253012048193
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 42.28915662650602
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.00803212851405
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 41.285140562249
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 39.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 37.59036144578313
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 37.14859437751004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.36546184738956
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 39.87951807228916
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 42.24899598393574
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 40.72289156626506
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 40.92369477911647
th siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.40963855421687
th mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 34.05622489959839
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 35.22088353413655
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 37.8714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 38.59437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 39.437751004016064
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 37.028112449799195
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 36.024096385542165
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 38.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.92369477911647
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 39.71887550200803
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 40.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 41.40562248995984
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 41.08433734939759
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 40.562248995983936
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 44.17670682730924
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.566265060240966
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 43.734939759036145
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 45.78313253012048
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 35.7429718875502
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 39.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 33.93574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 35.42168674698795
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 41.64658634538153
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 35.06024096385542
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 35.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 35.94377510040161
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 40.24096385542169
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 41.80722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 38.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 40.12048192771084
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 39.75903614457831
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 39.3574297188755
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 43.05220883534137
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 40.562248995983936
tr siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 48.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 49.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.8714859437751
tr mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 41.325301204819276
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.74698795180723
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.81526104417671
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 43.89558232931727
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 41.726907630522085
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 44.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 45.66265060240964
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 46.30522088353413
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 45.502008032128515
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 45.98393574297189
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 44.05622489959839
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 48.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 48.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 46.626506024096386
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 47.389558232931726
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 45.34136546184739
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 46.78714859437751
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 45.30120481927711
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 49.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 47.8714859437751
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 37.75100401606426
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 37.911646586345384
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 39.51807228915663
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 44.81927710843374
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.04016064257028
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 47.269076305220885
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 40.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 40.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 44.93975903614458
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 42.369477911646584
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.321285140562246
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 45.06024096385542
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 45.54216867469879
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.606425702811244
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 46.18473895582329
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 42.85140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 42.088353413654616
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 46.024096385542165
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 45.261044176706825
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 45.82329317269076
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 46.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 44.377510040160644
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 46.3855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 45.58232931726908
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 44.97991967871486
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 48.674698795180724
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 45.903614457831324
ur siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 40.40160642570281
ur mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 34.77911646586345
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 38.47389558232932
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 36.5863453815261
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 39.678714859437754
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 37.46987951807229
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 41.204819277108435
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 38.393574297188756
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 42.16867469879518
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 41.00401606425703
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 40.803212851405625
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 40.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 42.570281124497996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 40.48192771084337
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 40.441767068273094
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 42.93172690763052
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 40.963855421686745
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 43.93574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 42.44979919678715
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 39.59839357429719
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 43.6144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 41.12449799196787
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 42.69076305220884
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 40.40160642570281
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 35.70281124497992
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 40.602409638554214
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 35.98393574297189
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 41.04417670682731
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 36.144578313253014
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 39.63855421686747
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 37.83132530120482
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 40.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 41.4859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 38.95582329317269
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 36.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 39.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 40.6425702811245
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 38.433734939759034
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 40.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 40.08032128514056
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 42.65060240963855
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 39.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 38.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 40.28112449799197
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 37.429718875502004
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 38.11244979919679
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 39.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 41.16465863453815
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 39.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 39.799196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 39.31726907630522
vi siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 49.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 49.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 49.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 50.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 51.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 51.88755020080321
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 51.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 51.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 51.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 51.9277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 51.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 49.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 52.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 49.036144578313255
vi mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 37.18875502008032
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 38.99598393574297
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 47.51004016064257
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 44.65863453815261
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 49.558232931726906
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 49.91967871485944
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 48.273092369477915
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 49.83935742971887
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 49.11646586345382
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 50.68273092369478
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 46.94779116465863
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 51.285140562249
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 50.52208835341366
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 51.88755020080321
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 51.00401606425703
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 48.95582329317269
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 51.24497991967871
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 51.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 49.95983935742972
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 51.9277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 51.44578313253012
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 49.75903614457831
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 52.7710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 49.036144578313255
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 41.44578313253012
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 39.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.5140562248996
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 46.98795180722892
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 41.88755020080321
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 47.55020080321285
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.24497991967871
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 49.91967871485944
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 43.373493975903614
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 48.0722891566265
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 42.89156626506024
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 48.032128514056225
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 41.84738955823293
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 42.40963855421687
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 46.70682730923695
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 44.618473895582326
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 49.31726907630522
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 45.7429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 50.76305220883534
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 44.096385542168676
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 48.91566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 45.42168674698795
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 51.40562248995984
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.18875502008032
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 47.429718875502004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 46.22489959839358
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 51.12449799196787
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 48.15261044176707
zh siglyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 49.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 50.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 50.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 51.44578313253012
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 50.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 50.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 50.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 50.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 49.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 50.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 51.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 51.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 49.23694779116466
zh mltlyr:
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'siglyr')	||	accuracy: 39.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'siglyr')	||	accuracy: 43.25301204819277
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'siglyr')	||	accuracy: 39.23694779116466
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'siglyr')	||	accuracy: 43.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'siglyr')	||	accuracy: 45.46184738955823
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'siglyr')	||	accuracy: 43.57429718875502
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'siglyr')	||	accuracy: 47.71084337349398
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'siglyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'siglyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'siglyr')	||	accuracy: 49.397590361445786
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'siglyr')	||	accuracy: 47.911646586345384
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'siglyr')	||	accuracy: 46.46586345381526
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'siglyr')	||	accuracy: 49.3574297188755
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'siglyr')	||	accuracy: 48.5140562248996
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'siglyr')	||	accuracy: 48.63453815261044
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'siglyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'siglyr')	||	accuracy: 47.028112449799195
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'siglyr')	||	accuracy: 50.0
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'siglyr')	||	accuracy: 50.36144578313253
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'siglyr')	||	accuracy: 49.27710843373494
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'siglyr')	||	accuracy: 48.83534136546185
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'siglyr')	||	accuracy: 51.44578313253012
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'siglyr')	||	accuracy: 50.88353413654618
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'siglyr')	||	accuracy: 50.36144578313253
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'siglyr')	||	accuracy: 47.99196787148595
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'siglyr')	||	accuracy: 50.8433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'siglyr')	||	accuracy: 50.602409638554214
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'siglyr')	||	accuracy: 49.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'siglyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'siglyr')	||	accuracy: 50.72289156626506
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'siglyr')	||	accuracy: 51.64658634538153
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'siglyr')	||	accuracy: 48.87550200803213
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'siglyr')	||	accuracy: 49.47791164658634
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'siglyr')	||	accuracy: 51.08433734939759
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'siglyr')	||	accuracy: 49.23694779116466
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0, 'mltlyr')	||	accuracy: 40.88353413654618
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0, 'mltlyr')	||	accuracy: 38.63453815261044
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 0.5, 'mltlyr')	||	accuracy: 38.91566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 0.5, 'mltlyr')	||	accuracy: 33.333333333333336
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1, 'mltlyr')	||	accuracy: 47.95180722891566
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1, 'mltlyr')	||	accuracy: 41.52610441767068
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 1.5, 'mltlyr')	||	accuracy: 45.622489959839356
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 1.5, 'mltlyr')	||	accuracy: 41.9277108433735
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2, 'mltlyr')	||	accuracy: 49.558232931726906
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2, 'mltlyr')	||	accuracy: 42.329317269076306
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 2.5, 'mltlyr')	||	accuracy: 47.46987951807229
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 2.5, 'mltlyr')	||	accuracy: 42.48995983935743
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3, 'mltlyr')	||	accuracy: 46.907630522088354
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3, 'mltlyr')	||	accuracy: 44.69879518072289
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 3.5, 'mltlyr')	||	accuracy: 48.795180722891565
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 3.5, 'mltlyr')	||	accuracy: 40.16064257028113
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4, 'mltlyr')	||	accuracy: 47.14859437751004
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4, 'mltlyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 4.5, 'mltlyr')	||	accuracy: 47.59036144578313
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 4.5, 'mltlyr')	||	accuracy: 41.76706827309237
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5, 'mltlyr')	||	accuracy: 47.30923694779116
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5, 'mltlyr')	||	accuracy: 44.859437751004016
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 5.5, 'mltlyr')	||	accuracy: 49.51807228915663
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 5.5, 'mltlyr')	||	accuracy: 44.2570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6, 'mltlyr')	||	accuracy: 48.19277108433735
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6, 'mltlyr')	||	accuracy: 46.42570281124498
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 6.5, 'mltlyr')	||	accuracy: 49.799196787148595
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 6.5, 'mltlyr')	||	accuracy: 45.22088353413655
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7, 'mltlyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7, 'mltlyr')	||	accuracy: 46.666666666666664
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 7.5, 'mltlyr')	||	accuracy: 48.91566265060241
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 7.5, 'mltlyr')	||	accuracy: 46.34538152610442
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8, 'mltlyr')	||	accuracy: 47.06827309236948
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8, 'mltlyr')	||	accuracy: 48.23293172690763
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 8.5, 'mltlyr')	||	accuracy: 50.200803212851405
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 8.5, 'mltlyr')	||	accuracy: 47.10843373493976
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9, 'mltlyr')	||	accuracy: 48.31325301204819
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9, 'mltlyr')	||	accuracy: 47.791164658634536
(learning rate, dropout rate, epoch, layers): (5e-05, 0.1, 9.5, 'mltlyr')	||	accuracy: 49.11646586345382
(learning rate, dropout rate, epoch, layers): (0.0005, 0.1, 9.5, 'mltlyr')	||	accuracy: 49.1566265060241
